# PTZ Camera Self-Georegistration

This project provides a suite of tools to calculate the orientation of a PTZ (Pan-Tilt-Zoom) camera relative to a known reference map. The workflow involves three main stages: camera intrinsic calibration, reference alignment matrix (`R_align`) calibration, and finally, calculating the orientation offsets for new query images.

## Prerequisites

-   Python 3.9+
-   An NVIDIA GPU with CUDA drivers installed (for PyTorch acceleration).

## Setup Instructions

Follow these steps to set up the project environment.

**1. Unzip the Project**

First, unzip the provided project `.zip` file. This will create a project folder (likely named `ptz_self_georegistration`). Navigate into this directory from your terminal:

```bash
cd path/to/ptz_self_georegistration
```

**2. Create and Activate a Virtual Environment**

It is highly recommended to use a virtual environment to manage project dependencies.

*   On Windows:
    ```bash
    python -m venv .venv
    .\.venv\Scripts\activate
    ```
*   On macOS/Linux:
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```

### 3. Install PyTorch with CUDA Support

The version of PyTorch required by this project depends on your specific NVIDIA driver and CUDA version. The packages this project was developed with (`torch==2.8.0+cu129`) were built for **CUDA 12.9**.

**First, check your system's CUDA version.** Open your terminal (Command Prompt, PowerShell, or bash) and run the following command:
```bash
nvidia-smi
```
Look for the `CUDA Version` in the top right corner of the output. Your version must be equal to or higher than the version required by the PyTorch build you choose.

**Next, get the correct installation command:**

*   **If your CUDA version is 12.9 or compatible:** You can likely use the same command that was used for development. However, `+cu129` is not a standard PyTorch wheel. It is safer to use the official build for a slightly different CUDA version, like 12.1 or 12.4, which PyTorch officially supports. Modern drivers are forward-compatible.

*   **For all cases (Recommended):** Go to the [Official PyTorch Website](https://pytorch.org/get-started/locally/) and use their tool to generate the correct `pip` command. Select the options that match your system (e.g., Stable, Windows, Pip, Python, your CUDA version).

    For example, the official command for PyTorch with CUDA 12.1 is:
    ```bash
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

*Run the command generated by the website. This is the most reliable way to ensure PyTorch can use your GPU.*


**4. Install Remaining Packages**

Once PyTorch is installed, install the rest of the project's dependencies using the `requirements.txt` file included in the project.

```bash
pip install -r requirements.txt
```

**5. Install the Project Package in Editable Mode**

This step is essential for making the project's internal imports (`from ptz_georeg import ...`) work correctly. Run this command from the project root directory:
```bash
pip install -e .
```

## Configuration

All executable scripts are configured using `.ini` files located in the `configs/` directory. **Before running any script, you must modify the corresponding configuration file** to set the correct paths, parameters, and settings for your experiment.

-   `configs/camera_calibration.ini`: For calibrating camera intrinsics.
-   `configs/calibration.ini`: For calibrating the `R_align` matrix.
-   `configs/orientation_offsets.ini`: For calculating offsets of query images.

## Workflow and Usage

The main workflow is divided into three steps. Run these commands from the project's root directory.

### Step 1: Camera Intrinsics Calibration

This script calculates the camera's intrinsic matrix and distortion coefficients using chessboard images.

1.  **Configure:** Edit `configs/camera_calibration.ini`.
2.  **Run:**
    ```bash
    python scripts/camera_calibration.py --config configs/camera_calibration.ini
    ```
3.  **Output:** A `calibration.npz` file will be saved.

### Step 2: Calibrate Alignment Matrix (R_align)

This script uses a set of reference images to find the rotational alignment (`R_align`) between the camera's and world's coordinate systems.

1.  **Configure:** Edit `configs/calibration.ini`.
2.  **Run:**
    ```bash
    python scripts/calibrate_R_align.py --config configs/calibration.ini
    ```
3.  **Output:** An `R_align.npy` matrix will be saved.

### Step 3: Calculate Orientation Offsets

This script takes query images and uses the pre-computed intrinsics and `R_align` matrix to calculate their orientation offsets.

1.  **Configure:** Edit `configs/orientation_offsets.ini`.
2.  **Run:**
    ```bash
    python scripts/calculateOrientationOffsets.py --config configs/orientation_offsets.ini
    ```
3.  **Output:** An Excel file with the results will be saved.

## Monitoring and Notifications

### Slack Notifications

The project includes a Slack notification module for alerting on calibration status and offset thresholds.

**Setup (OAuth Token - Recommended):**

1. Create a Slack App and get an OAuth token:
   - Go to https://api.slack.com/apps
   - Create a new app or select an existing one
   - Navigate to "OAuth & Permissions"
   - Add the `chat:write` scope
   - Install the app to your workspace
   - Copy the "Bot User OAuth Token"

2. Set the access token as an environment variable:
   ```bash
   export SLACK_ACCESS_TOKEN="xoxb-your-token-here"
   export SLACK_CHANNEL="calibration-monitoring"  # Optional, defaults to "calibration-monitoring"
   ```

**Alternative Setup (Webhook URL):**

If you prefer using webhooks instead of OAuth tokens:

1. Create a webhook URL:
   - Go to https://api.slack.com/messaging/webhooks
   - Create a webhook for your `#calibration-monitoring` channel

2. Set the webhook URL:
   ```bash
   export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
   ```

**Usage:**

```python
from monitoring import SlackNotifier

# Initialize the notifier (auto-detects SLACK_ACCESS_TOKEN or SLACK_WEBHOOK_URL)
notifier = SlackNotifier()

# Send a calibration report
notifier.send_calibration_report(
    deployment="gan-shomron-dell",
    device_id="onvifcam-1",
    pitch=0.2,      # Pitch offset in degrees
    yaw=0.3,        # Yaw offset in degrees
    roll=0.1,       # Roll offset in degrees
    mode="passive", # or "active"
    success=True,   # Whether calibration succeeded
    failure_logs=["Optional error messages"]  # Include if success=False
)
```

**Alert Thresholds:**

- ðŸš¨ Alert emoji is shown if ANY offset exceeds 0.5Â°
- âœ… Success emoji is shown if all offsets are â‰¤ 0.5Â°

**Message Format:**

```
[âœ…/ðŸš¨] Camera Calibration Report
Deployment: gan-shomron-dell
Device: onvifcam-1
Timestamp: 2025-11-15T21:00:00Z
Offsets: Pitch=0.2Â°, Yaw=0.3Â°, Roll=0.1Â°
Mode: passive
Success: Yes
```

### AWS Integration Module

The `monitoring/aws_integration.py` module provides AWS infrastructure for calibration monitoring, including:

**Features:**

-   **Athena Table Schema**: Iceberg table for storing calibration results with columns for offsets, capture positions, file locations, and success/failure tracking
-   **S3 Utilities**: Upload/download functions for structured storage of images and features:
    -   Reference scans: `s3://camera-calibration-monitoring/{deployment}/{camera}/reference_scan/{images|features}/`
    -   Query scans: `s3://camera-calibration-monitoring/{deployment}/{camera}/query_scan/{timestamp}/{images|features}/`
-   **Athena Operations**: Write calibration results and query historical data

**Usage Example:**

```python
from monitoring.aws_integration import AWSIntegration, upload_reference_scan

# Initialize AWS integration
aws = AWSIntegration(region_name="us-east-1")

# Create the Athena table (one-time setup)
aws.create_table()

# Upload a reference scan
image_uris, feature_uris = upload_reference_scan(
    aws,
    deployment_name="deployment-1",
    camera_name="camera-01",
    images_dir="/path/to/images",
    features_dir="/path/to/features"
)

# Write calibration results
aws.write_calibration_result(
    deployment_name="deployment-1",
    device_id="camera-01",
    timestamp=datetime.now(),
    pitch_offset=0.5,
    yaw_offset=-0.3,
    roll_offset=0.1,
    mode="passive",
    capture_positions=[{"pan": 0.0, "tilt": 0.0, "zoom": 1.0}],
    files_location="s3://bucket/path/",
    success=True
)

# Query results
results = aws.query_calibration_results(
    deployment_name="deployment-1",
    device_id="camera-01",
    success_only=True
)
```

See `monitoring/aws_integration.py` and `monitoring/slack_notifier.py` for more detailed examples.

## Project Structure

```
ptz_self_georegistration/
â”œâ”€â”€ configs/                  # Configuration files for all executables.
â”œâ”€â”€ monitoring/               # Monitoring and notification modules.
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ slack_notifier.py    # Slack integration for calibration alerts.
â”‚   â”œâ”€â”€ aws_integration.py   # AWS integration module (S3, Athena).
â”‚   â”œâ”€â”€ example_usage.py     # Usage examples.
â”‚   â”œâ”€â”€ README.md            # Monitoring module documentation.
â”‚   â””â”€â”€ SLACK_SETUP.md       # Slack setup guide.
â”œâ”€â”€ ptz_georeg/               # The core Python library with all utility functions.
â”œâ”€â”€ scripts/                  # Executable scripts for the main workflow.
â”œâ”€â”€ requirements.txt          # List of Python package dependencies.
â”œâ”€â”€ setup.py                  # Makes the `ptz_georeg` folder installable.
â””â”€â”€ README.md                 # This file.
```