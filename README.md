# PTZ Camera Self-Georegistration

This project provides a suite of tools to calculate the orientation of a PTZ (Pan-Tilt-Zoom) camera relative to a known reference map. The workflow involves three main stages: camera intrinsic calibration, reference alignment matrix (`R_align`) calibration, and finally, calculating the orientation offsets for new query images.

## Prerequisites

-   Python 3.9+
-   An NVIDIA GPU with CUDA drivers installed (for PyTorch acceleration).

## Setup Instructions

Follow these steps to set up the project environment.

**1. Unzip the Project**

First, unzip the provided project `.zip` file. This will create a project folder (likely named `ptz_self_georegistration`). Navigate into this directory from your terminal:

```bash
cd path/to/ptz_self_georegistration
```

**2. Create and Activate a Virtual Environment**

It is highly recommended to use a virtual environment to manage project dependencies.

*   On Windows:
    ```bash
    python -m venv .venv
    .\.venv\Scripts\activate
    ```
*   On macOS/Linux:
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```

### 3. Install PyTorch with CUDA Support

The version of PyTorch required by this project depends on your specific NVIDIA driver and CUDA version. The packages this project was developed with (`torch==2.8.0+cu129`) were built for **CUDA 12.9**.

**First, check your system's CUDA version.** Open your terminal (Command Prompt, PowerShell, or bash) and run the following command:
```bash
nvidia-smi
```
Look for the `CUDA Version` in the top right corner of the output. Your version must be equal to or higher than the version required by the PyTorch build you choose.

**Next, get the correct installation command:**

*   **If your CUDA version is 12.9 or compatible:** You can likely use the same command that was used for development. However, `+cu129` is not a standard PyTorch wheel. It is safer to use the official build for a slightly different CUDA version, like 12.1 or 12.4, which PyTorch officially supports. Modern drivers are forward-compatible.

*   **For all cases (Recommended):** Go to the [Official PyTorch Website](https://pytorch.org/get-started/locally/) and use their tool to generate the correct `pip` command. Select the options that match your system (e.g., Stable, Windows, Pip, Python, your CUDA version).

    For example, the official command for PyTorch with CUDA 12.1 is:
    ```bash
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    ```

*Run the command generated by the website. This is the most reliable way to ensure PyTorch can use your GPU.*


**4. Install Remaining Packages**

Once PyTorch is installed, install the rest of the project's dependencies using the `requirements.txt` file included in the project.

```bash
pip install -r requirements.txt
```

**5. Install the Project Package in Editable Mode**

This step is essential for making the project's internal imports (`from ptz_georeg import ...`) work correctly. Run this command from the project root directory:
```bash
pip install -e .
```

## Configuration

All executable scripts are configured using `.ini` files located in the `configs/` directory. **Before running any script, you must modify the corresponding configuration file** to set the correct paths, parameters, and settings for your experiment.

-   `configs/camera_calibration.ini`: For calibrating camera intrinsics.
-   `configs/calibration.ini`: For calibrating the `R_align` matrix.
-   `configs/orientation_offsets.ini`: For calculating offsets of query images.

## Workflow and Usage

The main workflow is divided into three steps. Run these commands from the project's root directory.

### Step 1: Camera Intrinsics Calibration

This script calculates the camera's intrinsic matrix and distortion coefficients using chessboard images.

1.  **Configure:** Edit `configs/camera_calibration.ini`.
2.  **Run:**
    ```bash
    python scripts/camera_calibration.py --config configs/camera_calibration.ini
    ```
3.  **Output:** A `calibration.npz` file will be saved.

### Step 2: Calibrate Alignment Matrix (R_align)

This script uses a set of reference images to find the rotational alignment (`R_align`) between the camera's and world's coordinate systems.

1.  **Configure:** Edit `configs/calibration.ini`.
2.  **Run:**
    ```bash
    python scripts/calibrate_R_align.py --config configs/calibration.ini
    ```
3.  **Output:** An `R_align.npy` matrix will be saved.

### Step 3: Calculate Orientation Offsets

This script takes query images and uses the pre-computed intrinsics and `R_align` matrix to calculate their orientation offsets.

1.  **Configure:** Edit `configs/orientation_offsets.ini`.
2.  **Run:**
    ```bash
    python scripts/calculateOrientationOffsets.py --config configs/orientation_offsets.ini
    ```
3.  **Output:** An Excel file with the results will be saved.

## AWS Integration Module

The `monitoring/aws_integration.py` module provides AWS infrastructure for calibration monitoring, including:

### Features

-   **Athena Table Schema**: Iceberg table for storing calibration results with columns for offsets, capture positions, file locations, and success/failure tracking
-   **S3 Utilities**: Upload/download functions for structured storage of images and features:
    -   Reference scans: `s3://camera-calibration-monitoring/{deployment}/{camera}/reference_scan/{images|features}/`
    -   Query scans: `s3://camera-calibration-monitoring/{deployment}/{camera}/query_scan/{timestamp}/{images|features}/`
-   **Athena Operations**: Write calibration results and query historical data

### Usage Example

```python
from monitoring.aws_integration import AWSIntegration, upload_reference_scan

# Initialize AWS integration
aws = AWSIntegration(region_name="us-east-1")

# Create the Athena table (one-time setup)
aws.create_table()

# Upload a reference scan
image_uris, feature_uris = upload_reference_scan(
    aws,
    deployment_name="deployment-1",
    camera_name="camera-01",
    images_dir="/path/to/images",
    features_dir="/path/to/features"
)

# Write calibration results
aws.write_calibration_result(
    deployment_name="deployment-1",
    device_id="camera-01",
    timestamp=datetime.now(),
    pitch_offset=0.5,
    yaw_offset=-0.3,
    roll_offset=0.1,
    mode="passive",
    capture_positions=[{"pan": 0.0, "tilt": 0.0, "zoom": 1.0}],
    files_location="s3://bucket/path/",
    success=True
)

# Query results
results = aws.query_calibration_results(
    deployment_name="deployment-1",
    device_id="camera-01",
    success_only=True
)
```

See `monitoring/example_usage.py` for more detailed examples.

## Project Structure

```
ptz_self_georegistration/
├── configs/                  # Configuration files for all executables.
├── ptz_georeg/               # The core Python library with all utility functions.
├── monitoring/               # AWS integration module for calibration monitoring.
│   ├── aws_integration.py    # Main AWS integration module (S3, Athena).
│   └── example_usage.py      # Usage examples for the AWS integration.
├── scripts/                  # Executable scripts for the main workflow.
├── requirements.txt          # List of Python package dependencies.
├── setup.py                  # Makes the `ptz_georeg` folder installable.
└── README.md                 # This file.
```